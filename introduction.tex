\section{Introduction}
\label{sec:introduction}

Multithreaded programming has become very popular with the multi-core
revolution that spread in the last two decades.
%
This has allowed, in the High Performance Computing (HPC) world, to adopt
on-node parallelism to a greater degree in large software applications
development especially to guarantee the future required performance and power
budgets.
%
In support of this argument, HPC is undergoing an explosion in
computing capabilities, which is confirmed by the work-in-progress of the
next-generation of supercomputer projects in the main national research
facilities of the country~\cite{sierra, summit, trinity}.
%
Multithreaded programming is achieved through different programming models
(e.g. Pthreads), however the predominant paradigm of choice in HPC is
OpenMP~\cite{ompdoc}, which guarantees portability and ease of use.
%
In fact, we are collaborating with computational scientists at Lawrence
Livermore National Laboratory (LLNL), one of the world's largest computing
facilities, where the current main task is the porting of critical
multiphysics application~\cite{llnl-apps} to OpenMP.

OpenMP is paramount to portable shared memory parallel programming - yet,
porting large HPC applications to OpenMP is error-prone.
%
The correctness of these applications is crucial to the reliability of the
simulations pertaining to many real world phenomena of fundamental importance
such as modeling of nuclear explosions, weather simulations, hydrodynamics
modeling, etc.
%
The most common errors in OpenMP applications are data
races~\cite{sus_common_2008}.
%
Data races are often hard to find with traditional debugging methods.
%
Precise checking tools to detect these kinds of errors are needed now more
than ever.
%
While data race is a well-known problem and many Pthreads data race detection
tools have been proposed over the past twenty years, none or just a few of
them are actually able to analyze OpenMP programs.

Data race detection research has focused both on static and dynamic analysis
techniques.
%
Static analysis techniques allow to reason about all the inputs of the program
and the interleavings of the threads, and they are fairly scalable and fast
since no runtime overhead is generated.
%
However, the lack of information that exists only at runtime makes these
techniques very imprecise, in fact they often miss races and report many false
positives.
%
While runtime techniques are very precise, they do not report any false
positives and reports the races in the branches of the programs that are
actually executed if any.
%
On the other hand dynamic analysis for data race detection is known to
generate a very high runtime and memory overhead due to the operations it
needs to perform and the states it needs to maintain during the execution.

The runtime overhead for the best tools, such as ThreadSanitizer (Tsan) and
Intel Inspector XE, can introduce between $5x-20x$ slowdown and the memory
overhead can be between $2x-10x$ the memory used by the normal execution of
the programs.
%
For very large programs, such as HPC applications, the runtime and memory
overhead can be even bigger, experiments show that the slowdown can be $100x$
and the memory consumption can be $50x$ larger.
%
The high runtime slowdown and memory usage make such tools useless from the
point of view of the developers, whom probably would not be keen to wait a
long time to check their programs or they may not even have enough machine
resources to run the tools.
%
We definitely need better techniques, either static or dynamic, to detect data
races in large structured parallel applications, that guarantee precision and
accuracy using a fairly small amount of runtime and memory resources.

\emph{The goal of this dissertation is to provide a sound and precise data
  race detection tool for large OpenMP applications that combine static and
  dynamic analysis while maintaining a low runtime and memory overhead.}
%
First, we combine static and existing dynamic techniques to reduce the amount
of code to analyze at runtime and so lower the overheads.
%
Second, we will develop a new runtime technique for data race detection that
exploits the structured parallelism of OpenMP to reduce runtime and memory
overhead, while guaranteeing high precision and accuracy.
%
Our contributions are listed as follow:

\begin{itemize}
\item \textbf{Sequential Blacklisting:} We will design a static analysis to
  identify the code executed sequentially in a OpenMP program.
\item \textbf{Data Dependency Analysis:} We will design a static analysis
  technique that identify race free code in a OpenMP program to exclude it
  from the runtime analysis.
\item \textbf{\archer v1:} We will combine the static analysis with the
  existing Clang/LLVM Tsan data race detection tool and we will make Tsan
  capable of detect data races in OpenMP programs, as part of a first version
  of a data race detector called \archer.
\item \textbf{Clock-less runtime algorithm:} We will design and implement a
  new runtime analysis technique that exploit the structured parallelism of
  the OpenMP paradigm in order to reduce the runtime and memory overhead.
\item \textbf{\archer v2:} We will embed the aforementioned new runtime
  technique in a second version of \archer as a replacement of the \tsan
  runtime.
\end{itemize}

%%% Local Variables:
%%% mode: latex
%%% eval: (flyspell-mode 1)
%%% TeX-master: "root.tex"
%%% End:
